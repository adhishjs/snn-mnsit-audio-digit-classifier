# ğŸ§ ğŸ”Š Spiking Neural Network for Audio MNIST Digit Classification

This project implements a Spiking Neural Network (SNN) to classify spoken digits (0â€“9) using audio recordings. The model is trained and evaluated using MFCC features extracted from audio samples â€” a biologically inspired approach leveraging temporal dynamics!

## ğŸ“ Project Structure

<pre>

AUDIO/
â”œâ”€â”€ DATASET/              # (Optional) Original dataset folder
â”œâ”€â”€ DATASET_TEST/         # Test samples (preprocessed)
â”œâ”€â”€ SNN_network.py        # Simple SNN architecture
â”œâ”€â”€ run_digit.py          # Script to evaluate test audio digits
â”œâ”€â”€ train_digit.py        # Script to train the model
â”œâ”€â”€ ds_loader.py          # Data loading and preprocessing logic
â”œâ”€â”€ encoder.py            # Audio to spike encoding logic
â”œâ”€â”€ loading.py            # Utility to load model checkpoints
â”œâ”€â”€ saving.py             # Utility to save model checkpoints
â”œâ”€â”€ audio_rec.py          # Optional audio recording
â”œâ”€â”€ parameters.pt         # Trained model parameters

</pre>

ğŸš€ How to Run

1. ğŸ“¦ Requirements
   Install the required Python packages:

```bash
pip install torch torchaudio numpy
```

2. ğŸ§ Dataset
   Ensure you have the preprocessed MFCC dataset in the DATASET_TEST/ folder. Each file should be an audio sample corresponding to a digit from 0 to 9.

For Dataset,

https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist/data



4. ğŸ Run Inference
   To test the model on random 10 audio samples:

```bash
python run_digit.py
```

4. ğŸ§  Train the Model
   If you want to train your own model from scratch:

```bash
python train_digit.py
```

The trained model will be saved as parameters.pt.


ğŸ” Model Overview
<pre>
The model is a SimpleSNN:

Input: MFCC features â†’ Spike Trains

Architecture: Feedforward spiking layers

Activation: Leaky Integrate-and-Fire (LIF) dynamics

Output: 10-class softmax layer (digit prediction)
</pre>


The model uses a biologically inspired temporal encoding mechanism.

encoder.py handles converting audio features into spike trains.

You can record new audio with audio_rec.py and test it live.

ğŸ§  Inspiration
   This project blends neuroscience with modern machine learning â€” showing how SNNs can interpret temporal signals like speech.



Made by Adhish J S

For Contact,
adhishjs05@gmail.com 
